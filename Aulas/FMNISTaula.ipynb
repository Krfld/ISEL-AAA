{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.datasets as DT\n",
    "import numpy.random as rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X1, y1), (X2, y2) = DT.fashion_mnist.load_data()\n",
    "print(\"Training set:\", X1.shape, X1.dtype)\n",
    "print(\"Test set:    \", X2.shape, X2.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxList = []\n",
    "for i in range(10):\n",
    "    idxTemp = np.argwhere(y1 == i).squeeze()\n",
    "    idxList.append(idxTemp)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    idx = idxList[i]\n",
    "    for n in range(20):\n",
    "        if n == 0:\n",
    "            Img = np.hstack((255 - X1[idx[n]], np.ones((28, 3)) * 255))\n",
    "        else:\n",
    "            Img = np.hstack((Img, 255 - X1[idx[n]], np.ones((28, 3)) * 255))\n",
    "\n",
    "    if i == 0:\n",
    "        ImgT = np.vstack((Img, np.ones((3, Img.shape[1])) * 255))\n",
    "    else:\n",
    "        ImgT = np.vstack((ImgT, Img, np.ones((3, Img.shape[1])) * 255))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(ImgT, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle training set and sort test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = rd.permutation(X1.shape[0])\n",
    "X1 = X1[idx]\n",
    "y1 = y1[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(y2)\n",
    "y2 = y2[idx]\n",
    "X2 = X2[idx]\n",
    "plt.plot(y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images must be in vector format (make sure that data is in \"float\" format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X1.reshape((60000, 28**2)) * 1.0\n",
    "X2 = X2.reshape((X2.shape[0], 28**2)) * 1.0\n",
    "print(\"Training set:\", X1.shape, X1.dtype)\n",
    "print(\"Test set:    \", X2.shape, X2.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, predict and check confusion matrix - use SGDClassifier (try others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier().fit(X1, y1)\n",
    "y2e = sgd.predict(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y2, y2e))\n",
    "print(\"Total number of erros %d (in %d)\" % (np.sum(y2 != y2e), X2.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since test set is ordered, one can also check erros visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(y2e, \".\", alpha=0.5)\n",
    "plt.plot(y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible problem: different means and variances of each of the 784 data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.mean(X1, axis=0)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(m, \".-\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Means\")\n",
    "\n",
    "s = np.std(X1, axis=0)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(s, \".-\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Standard Deviations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data (0 mean and unit variance in each dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler().fit(X1)\n",
    "X1s = sc.transform(X1)\n",
    "X2s = sc.transform(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier().fit(X1s, y1)\n",
    "y2e = sgd.predict(X2s)\n",
    "print(confusion_matrix(y2, y2e))\n",
    "print(\"Total number of erros %d (in %d)\" % (np.sum(y2 != y2e), X2.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data with PCA - use different values for total variance\n",
    "## Repeat the process with the normalized data (StandarScaler) to check if it is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.9, whiten=True).fit(X1)\n",
    "X1p = pca.transform(X1)\n",
    "X2p = pca.transform(X2)\n",
    "print(\"NÂº of Principal Components kept: %d\" % X1p.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier().fit(X1p, y1)\n",
    "y2e = sgd.predict(X2p)\n",
    "print(confusion_matrix(y2, y2e))\n",
    "print(\"Total number of erros %d (in %d)\" % (np.sum(y2 != y2e), X2.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification problem (positives are class 3 - dresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1b = (y1 == 3) * 1\n",
    "y2b = (y2 == 3) * 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier().fit(X1p, y1b)\n",
    "y2e = sgd.predict(X2p)\n",
    "print(confusion_matrix(y2b, y2e))\n",
    "print(\"Total number of erros %d (in %d)\" % (np.sum(y2b != y2e), y2b.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.sum(y2e[y2b == 1] == 1) / (\n",
    "    np.sum(y2e[y2b == 1] == 1) + np.sum(y2e[y2b == 1] == 0)\n",
    ")  # recall\n",
    "p1 = np.sum(y2e[y2b == 1] == 1) / (\n",
    "    np.sum(y2e[y2b == 1] == 1) + np.sum(y2e[y2b == 0] == 1)\n",
    ")  # precision\n",
    "f1 = np.sum(y2e[y2b == 0] == 1) / (\n",
    "    np.sum(y2e[y2b == 0] == 0) + np.sum(y2e[y2b == 0] == 1)\n",
    ")  # fp-rate\n",
    "print(\"Recall: %3f - Precision: %3f - FP-rate: %3f\" % (r1, p1, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y2b, y2e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Calibration (changing decision threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2e = sgd.decision_function(X2p)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(r2e)\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y2b, (r2e >= 0) * 1))  # default threshold\n",
    "print(\n",
    "    \"Total number of erros %d (in %d)\" % (np.sum(y2b != (r2e >= 0) * 1), y2b.shape[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change threshold - reduce the false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim2 = -0.191\n",
    "y2eB = (r2e > lim2) * 1\n",
    "print(confusion_matrix(y2b, y2eB))\n",
    "print(\"Total number of erros %d (in %d)\" % (np.sum(y2b != y2eB), y2b.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = np.sum(y2eB[y2b == 1] == 1) / (\n",
    "    np.sum(y2eB[y2b == 1] == 1) + np.sum(y2eB[y2b == 1] == 0)\n",
    ")\n",
    "p2 = np.sum(y2eB[y2b == 1] == 1) / (\n",
    "    np.sum(y2eB[y2b == 1] == 1) + np.sum(y2eB[y2b == 0] == 1)\n",
    ")\n",
    "f2 = np.sum(y2eB[y2b == 0] == 1) / (\n",
    "    np.sum(y2eB[y2b == 0] == 0) + np.sum(y2eB[y2b == 0] == 1)\n",
    ")\n",
    "print(\"Recall: %3f - Precision: %3f - FP-rate: %3f\" % (r2, p2, f2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim3 = -1.75\n",
    "y2eC = (r2e > lim3) * 1\n",
    "print(confusion_matrix(y2b, y2eC))\n",
    "print(\"Total number of erros %d (in %d)\" % (np.sum(y2b != y2eC), y2.shape[0]))\n",
    "r3 = np.sum(y2eC[y2b == 1] == 1) / (\n",
    "    np.sum(y2eC[y2b == 1] == 1) + np.sum(y2eC[y2b == 1] == 0)\n",
    ")\n",
    "p3 = np.sum(y2eC[y2b == 1] == 1) / (\n",
    "    np.sum(y2eC[y2b == 1] == 1) + np.sum(y2eC[y2b == 0] == 1)\n",
    ")\n",
    "f3 = np.sum(y2eC[y2b == 0] == 1) / (\n",
    "    np.sum(y2eC[y2b == 0] == 0) + np.sum(y2eC[y2b == 0] == 1)\n",
    ")\n",
    "print(\"Recall: %3f - Precision: %3f - FP-rate: %3f\" % (r3, p3, f3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve + Precision-recall curve - 3 thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp, tp, t = skm.roc_curve(y2b, r2e)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fp, tp)\n",
    "plt.plot(f1, r1, \"or\")\n",
    "plt.plot(f2, r2, \"ob\")\n",
    "plt.plot(f3, r3, \"og\")\n",
    "\n",
    "plt.axis(\"scaled\")\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre, rec, lim = skm.precision_recall_curve(y2b, r2e)\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(pre, rec)\n",
    "plt.plot(p1, r1, \"or\")\n",
    "plt.plot(p2, r2, \"ob\")\n",
    "plt.plot(p3, r3, \"og\")\n",
    "\n",
    "plt.axis(\"scaled\")\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precion, Recall and F-score  for the thresholds used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(lim, pre[:-1], \"b\")\n",
    "plt.plot(lim, rec[:-1], \"r\")\n",
    "fsc = 2 * pre * rec / (pre + rec)\n",
    "plt.plot(lim, fsc[:-1], \"g\")\n",
    "\n",
    "plt.plot(0, p1, \"or\")\n",
    "plt.plot(0, r1, \"or\")\n",
    "plt.plot(lim2, p2, \"ob\")\n",
    "plt.plot(lim2, r2, \"ob\")\n",
    "plt.plot(lim3, p3, \"og\")\n",
    "plt.plot(lim3, r3, \"og\")\n",
    "\n",
    "plt.axis([np.floor(lim.min()), np.ceil(lim.max()), 0, 1])\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.floor(lim.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison (try another classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RandF = RandomForestClassifier().fit(X1p, y1b)\n",
    "y2f = RandF.predict(X2p)\n",
    "print(confusion_matrix(y2b, y2f))\n",
    "print(\"Total number of erros %d (in %d)\" % (np.sum(y2b != y2f), y2b.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2f = RandF.predict_proba(X2p)[:, 1]\n",
    "yB = (r2f > 0.5) * 1  # default threshold\n",
    "print(confusion_matrix(y2b, yB))\n",
    "print(\"Total number of erros %d (in %d)\" % (np.sum(y2b != yB), y2b.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp, tp, t = skm.roc_curve(y2b, r2e)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fp, tp, color=[0.3, 0.6, 0.1])\n",
    "plt.text(0.2, 0.8, \"SGDClassifier\", fontsize=14, color=[0.3, 0.6, 0.1])\n",
    "\n",
    "plt.plot(f1, r1, \"or\")\n",
    "plt.plot(f2, r2, \"ob\")\n",
    "plt.plot(f3, r3, \"og\")\n",
    "\n",
    "fp2, tp2, t2 = skm.roc_curve(y2b, r2f)\n",
    "r4 = np.sum(yB[y2b == 1] == 1) / (np.sum(yB[y2b == 1] == 1) + np.sum(yB[y2b == 1] == 0))\n",
    "p4 = np.sum(yB[y2b == 1] == 1) / (np.sum(yB[y2b == 1] == 1) + np.sum(yB[y2b == 0] == 1))\n",
    "f4 = np.sum(yB[y2b == 0] == 1) / (np.sum(yB[y2b == 0] == 0) + np.sum(yB[y2b == 0] == 1))\n",
    "print(\"Recall: %3f - Precision: %3f - FP-rate: %3f\" % (r2, p2, f2))\n",
    "plt.plot(fp2, tp2, color=[0.9, 0.3, 0.2])\n",
    "plt.text(\n",
    "    0.2, 0.85, \"RandomForest (needs calibration)\", fontsize=14, color=[0.9, 0.3, 0.2]\n",
    ")\n",
    "\n",
    "plt.plot(f4, r4, \".\", ms=15, color=[0.9, 0.3, 0.2])\n",
    "plt.axis(\"scaled\")\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
