{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Network without Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# load data\n",
    "D = pickle.load(open(\"xorData.p\", \"rb\"))\n",
    "# print(D)\n",
    "\n",
    "X = D.data - 0.5 # Compensate the inputs offset\n",
    "y = D.target\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "# print(X1[:,0])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X[0, y == 0], X[1, y == 0], '.')\n",
    "plt.plot(X[0, y == 1], X[1, y == 1], '.')\n",
    "# plt.plot(X[0, :], X[1, :], '.')\n",
    "# plt.plot(y1, y1, '.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network training algorithm a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    hidden_units=10,\n",
    "    adaptation_step=1e-5,  # eta\n",
    "    moment_term=0.9,  # alpha\n",
    "    number_of_iterations=500,  # iter\n",
    "    activation_function=np.tanh,\n",
    "):\n",
    "\n",
    "    # Each row for each input\n",
    "    # Each column for each hidden neuron\n",
    "    # Start the hidden layer weights with low random values\n",
    "    Wi = rd.randn(2, hidden_units) * .1\n",
    "    # print(Wi)\n",
    "\n",
    "    # Each row for each hidden neuron\n",
    "    b = np.zeros((hidden_units, 1))\n",
    "    # print(b)\n",
    "\n",
    "    # Each row for the output of each hidden neuron\n",
    "    # Start the output layer weights with low random values\n",
    "    Wo = rd.randn(hidden_units, 1) * .1\n",
    "    # print(Wo)\n",
    "\n",
    "    # Bias for the output layer\n",
    "    bo = 0\n",
    "\n",
    "    # Initialize the derivatives\n",
    "    dzWi = np.zeros(Wi.shape)\n",
    "    dzb = np.zeros(b.shape)\n",
    "    dzWo = np.zeros(Wo.shape)\n",
    "    dzbo = 0\n",
    "\n",
    "    Error = np.zeros(number_of_iterations)\n",
    "\n",
    "    for n in range(number_of_iterations):\n",
    "        # forward pass\n",
    "        u = np.dot(Wi.T, X) + b\n",
    "        v = activation_function(u)\n",
    "        z = np.dot(Wo.T, v) + bo\n",
    "        yh = activation_function(z)\n",
    "\n",
    "        # error\n",
    "        E = y-yh\n",
    "        Error[n] = np.mean(E**2)\n",
    "\n",
    "        # gradient\n",
    "        dz = -2*E*(1-yh**2)\n",
    "        dbo = np.sum(dz)\n",
    "        dWo = np.dot(v, dz.T)\n",
    "        du = (1-v**2)*np.dot(Wo, dz)\n",
    "        db = np.sum(du, axis=1)\n",
    "        dWi = np.dot(X, du.T)\n",
    "\n",
    "        # adapt\n",
    "        dzWi = moment_term * dzWi + dWi\n",
    "        dzb = moment_term * dzb + db[:, np.newaxis]\n",
    "        dzWo = moment_term * dzWo + dWo\n",
    "        dzbo = moment_term * dzbo + dbo\n",
    "\n",
    "        Wi = Wi - adaptation_step * dzWi\n",
    "        b = b - adaptation_step * dzb\n",
    "        Wo = Wo - adaptation_step * dzWo\n",
    "        bo = bo - adaptation_step * dzbo\n",
    "\n",
    "    return Error, yh, Wi, b, Wo, bo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network b) c) d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1, 10 and 50 hidden units\n",
    "for hu in [1, 10, 50]:\n",
    "    print(\"Hidden units:\", hu)\n",
    "    best = 1\n",
    "    best_error = []\n",
    "    best_yh = []\n",
    "    best_eta = 0\n",
    "    best_alpha = 0\n",
    "    best_Wi = []\n",
    "    best_b = []\n",
    "    best_Wo = []\n",
    "    best_bo = 0\n",
    "    for eta in np.linspace(1e-5, 1e-3, 10):\n",
    "        for alpha in np.linspace(0.9, 0.99, 10):\n",
    "            Error, yh, Wi, b, Wo, bo = train(X, y,\n",
    "                                             hidden_units=hu,\n",
    "                                             adaptation_step=eta,  # eta\n",
    "                                             moment_term=alpha,  # alpha\n",
    "                                             number_of_iterations=500,  # iter\n",
    "                                             )\n",
    "\n",
    "            if Error[len(Error)-1] < best:\n",
    "                best = Error[len(Error)-1]\n",
    "                best_error = Error.copy()\n",
    "                best_yh = yh.copy()\n",
    "                best_Wi = Wi.copy()\n",
    "                best_b = b.copy()\n",
    "                best_Wo = Wo.copy()\n",
    "                best_bo = bo\n",
    "                best_eta = eta\n",
    "                best_alpha = alpha\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(best_error)\n",
    "    plt.title('Error: ' + str(best) +\n",
    "              '\\nHidden Units: ' + str(hu) +\n",
    "              '\\neta: ' + str(best_eta) +\n",
    "              '\\nalpha: ' + str(best_alpha) +\n",
    "              '\\niter: ' + str(len(best_error)))\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Training set errors\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ye = (best_yh.squeeze() >= 0.5)\n",
    "    plt.plot(X[0, y == 0], X[1, y == 0], '.b')\n",
    "    plt.plot(X[0, y == 1], X[1, y == 1], '.r')\n",
    "    plt.plot(X[0, y != ye], X[1, y != ye], 'ok', alpha=.7)\n",
    "    plt.show()\n",
    "    print('Nº of errors:', np.sum(y != ye))\n",
    "\n",
    "    # Wireframe\n",
    "\n",
    "    gX, gY = np.meshgrid(np.linspace(-1, 2, 50), np.linspace(-1, 2, 50))\n",
    "    X2 = np.vstack((gX.ravel(), gY.ravel()))\n",
    "    u = np.dot(best_Wi.T, X2)+best_b\n",
    "    v = np.tanh(u)\n",
    "    z = np.dot(best_Wo.T, v)\n",
    "    yh = np.tanh(z+best_bo)\n",
    "    Yh = np.reshape(yh, (50, 50))\n",
    "\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    # ax.contour3D(gX,gY,Yh,50,cmap='binary')\n",
    "    ax.plot_wireframe(gX, gY, Yh)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that when we train with 1 hidden unit, the network is not able to learn the function because with only 1 hidden unit, there's no way differentiate the data with an intersection\n",
    "\n",
    "With 10 or 50 units we see not much difference, indicating that adding more hidden units is not usefull. Maybe a better result could be achieved increasing the number of hidden layers instead of the number of hidden units\n",
    "\n",
    "We can see that the best alpha is close to 1 because at the end of the iterations, the network was able to reach that error value relatively fast compared to other alpha values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Network with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,)\n",
      "(10000, 32, 32, 3) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from skimage import color\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(Xtrain, ytrain), (Xtest, ytest) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "Xtrain = Xtrain.astype('float32')\n",
    "Xtest = Xtest.astype('float32')\n",
    "Xtrain /= 255\n",
    "Xtest /= 255\n",
    "\n",
    "# Transform data into array from 1-col matrix\n",
    "ytrain = ytrain.squeeze()\n",
    "ytest = ytest.squeeze()\n",
    "\n",
    "print(Xtrain.shape, ytrain.shape)\n",
    "print(Xtest.shape, ytest.shape)\n",
    "\n",
    "# Randomize train data\n",
    "idx = rd.permutation(Xtrain.shape[0])\n",
    "Xtrain = Xtrain[idx]\n",
    "ytrain = ytrain[idx]\n",
    "\n",
    "# Sort test data\n",
    "idx = np.argsort(ytest)\n",
    "Xtest = Xtest[idx]\n",
    "ytest = ytest[idx]\n",
    "\n",
    "# Convert to grayscale\n",
    "XtrainG = np.zeros((Xtrain.shape[0], 32, 32))\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    XtrainG[i] = color.rgb2gray(Xtrain[i])\n",
    "\n",
    "XtestG = np.zeros((Xtest.shape[0], 32, 32))\n",
    "for i in range(Xtest.shape[0]):\n",
    "    XtestG[i] = color.rgb2gray(Xtest[i])\n",
    "\n",
    "# Convert to vector\n",
    "XtrainGV = XtrainG.reshape((XtrainG.shape[0], XtrainG.shape[1] ** 2)) * 1.0\n",
    "XtestGV = XtestG.reshape((XtestG.shape[0], XtestG.shape[1] ** 2)) * 1.0\n",
    "\n",
    "# Categorical\n",
    "ytrainC = keras.utils.to_categorical(ytrain)\n",
    "ytestC = keras.utils.to_categorical(ytest)\n",
    "\n",
    "X1_train, X1_val, y1_train, y1_val = train_test_split(\n",
    "    XtrainGV, ytrainC, test_size=0.1)\n",
    "\n",
    "# Pre-processing\n",
    "ss = StandardScaler().fit(XtrainGV)\n",
    "XtrainGVp = ss.transform(XtrainGV)\n",
    "XtestGVp = ss.transform(XtestGV)\n",
    "X1_trainP = ss.transform(X1_train)\n",
    "X1_valP = ss.transform(X1_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = XtrainGV\n",
    "y1 = ytrain\n",
    "y1C = ytrainC\n",
    "\n",
    "X1p = XtrainGVp\n",
    "X1s = X1_train\n",
    "X1sp = X1_trainP\n",
    "X1sVal = X1_val\n",
    "X1sValP = X1_valP\n",
    "y1s = y1_train\n",
    "y1sVal = y1_val\n",
    "\n",
    "X2 = XtestGV\n",
    "X2p = XtestGVp\n",
    "y2 = ytest\n",
    "y2C = ytestC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = keras.Sequential()\n",
    "nn.add(keras.layers.Flatten(input_shape=(32*32,)))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "nn.compile(optimizer=\"nadam\",\n",
    "           loss=keras.losses.mean_squared_error,\n",
    "           metrics=[\"accuracy\"],\n",
    "           )\n",
    "\n",
    "print(nn.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = nn.fit(X1, y1C,\n",
    "               epochs=50,\n",
    "               batch_size=1024,\n",
    "               validation_data=(X2, y2C),\n",
    "               use_multiprocessing=True,\n",
    "               )\n",
    "\n",
    "h = train.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2e = nn.predict(X2)\n",
    "y2p = np.argmax(y2e, axis=1)\n",
    "\n",
    "print('Nº of errors:', np.sum(y2 != y2p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the accuracy increasing, the val_accuracy doesn't improve, indicating that the network stopped learning for new inputs and is now memorizing the training data\n",
    "We confirm that seeing that the val_loss started increasing a little bit at 50 epochs +-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 281,098\n",
      "Trainable params: 281,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 210ms/step - loss: 2.3004 - accuracy: 0.1108 - val_loss: 2.2963 - val_accuracy: 0.1192\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 2.2967 - accuracy: 0.1376 - val_loss: 2.2956 - val_accuracy: 0.1108\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2.2752 - accuracy: 0.1383 - val_loss: 2.2766 - val_accuracy: 0.1344\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2.2701 - accuracy: 0.1318 - val_loss: 2.2567 - val_accuracy: 0.1308\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 2.2509 - accuracy: 0.1376 - val_loss: 2.1954 - val_accuracy: 0.1598\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 2.2600 - accuracy: 0.1425 - val_loss: 2.2097 - val_accuracy: 0.1810\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 2.2009 - accuracy: 0.1662 - val_loss: 2.1824 - val_accuracy: 0.1612\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 2.2372 - accuracy: 0.1472 - val_loss: 2.1948 - val_accuracy: 0.1752\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 2.1887 - accuracy: 0.1721 - val_loss: 2.1956 - val_accuracy: 0.1830\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 2.2052 - accuracy: 0.1682 - val_loss: 2.1550 - val_accuracy: 0.1898\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 2.1922 - accuracy: 0.1662 - val_loss: 2.1970 - val_accuracy: 0.1598\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 2.1747 - accuracy: 0.1818 - val_loss: 2.2110 - val_accuracy: 0.1720\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 2.1925 - accuracy: 0.1764 - val_loss: 2.1496 - val_accuracy: 0.1892\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 2.1955 - accuracy: 0.1748 - val_loss: 2.1734 - val_accuracy: 0.1866\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 2.1816 - accuracy: 0.1798 - val_loss: 2.2016 - val_accuracy: 0.1650\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 2.1866 - accuracy: 0.1762 - val_loss: 2.2381 - val_accuracy: 0.1648\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 2.1787 - accuracy: 0.1876 - val_loss: 2.1568 - val_accuracy: 0.1696\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 2.1267 - accuracy: 0.2015 - val_loss: 2.2123 - val_accuracy: 0.1670\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 2.2558 - accuracy: 0.1477 - val_loss: 2.1736 - val_accuracy: 0.1722\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 2.1643 - accuracy: 0.1755 - val_loss: 2.1888 - val_accuracy: 0.1814\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 2.1813 - accuracy: 0.1753 - val_loss: 2.1253 - val_accuracy: 0.2018\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 2.1208 - accuracy: 0.2078 - val_loss: 2.1386 - val_accuracy: 0.1868\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 2.1856 - accuracy: 0.1736 - val_loss: 2.1389 - val_accuracy: 0.1950\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 2.1107 - accuracy: 0.2170 - val_loss: 2.1758 - val_accuracy: 0.1934\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 2.1492 - accuracy: 0.2033 - val_loss: 2.0712 - val_accuracy: 0.2448\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 2.0949 - accuracy: 0.2266 - val_loss: 2.1331 - val_accuracy: 0.2180\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 2.1563 - accuracy: 0.1918 - val_loss: 2.1058 - val_accuracy: 0.2342\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 2.0900 - accuracy: 0.2302 - val_loss: 2.0821 - val_accuracy: 0.2330\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 2.1560 - accuracy: 0.1965 - val_loss: 2.1223 - val_accuracy: 0.2112\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 2.0937 - accuracy: 0.2223 - val_loss: 2.0667 - val_accuracy: 0.2502\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 2.0867 - accuracy: 0.2384 - val_loss: 2.0898 - val_accuracy: 0.2270\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 2.0624 - accuracy: 0.2409 - val_loss: 2.1250 - val_accuracy: 0.1932\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 2.1235 - accuracy: 0.2135 - val_loss: 2.0625 - val_accuracy: 0.2378\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 2.0633 - accuracy: 0.2437 - val_loss: 2.0275 - val_accuracy: 0.2666\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 2.0484 - accuracy: 0.2538 - val_loss: 2.0446 - val_accuracy: 0.2420\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 2.0295 - accuracy: 0.2562 - val_loss: 2.1836 - val_accuracy: 0.2040\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 2.1004 - accuracy: 0.2286 - val_loss: 2.0202 - val_accuracy: 0.2768\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 2.0103 - accuracy: 0.2713 - val_loss: 2.0294 - val_accuracy: 0.2592\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 2.0053 - accuracy: 0.2718 - val_loss: 2.0162 - val_accuracy: 0.2634\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 2.0650 - accuracy: 0.2459 - val_loss: 2.0632 - val_accuracy: 0.2452\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 2.0199 - accuracy: 0.2659 - val_loss: 2.0010 - val_accuracy: 0.2792\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 2.0261 - accuracy: 0.2630 - val_loss: 1.9907 - val_accuracy: 0.2826\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 1.9941 - accuracy: 0.2729 - val_loss: 2.0108 - val_accuracy: 0.2668\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 1.9814 - accuracy: 0.2848 - val_loss: 1.9931 - val_accuracy: 0.2856\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 2.0142 - accuracy: 0.2736 - val_loss: 1.9703 - val_accuracy: 0.2864\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 1.9730 - accuracy: 0.2899 - val_loss: 2.0157 - val_accuracy: 0.2526\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.0530 - accuracy: 0.2463"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_105972\\1129946697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1sVal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1sVal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                )\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1079\u001b[0m                 step_num=step):\n\u001b[0;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    616\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32md:\\OneDrive - Instituto Superior de Engenharia de Lisboa\\Mestrado\\Semestre 2\\AVII\\ML Agents\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn = keras.Sequential()\n",
    "nn.add(keras.layers.Flatten(input_shape=(32*32,)))\n",
    "nn.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dropout(0.2))\n",
    "nn.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dropout(0.2))\n",
    "nn.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dropout(0.2))\n",
    "nn.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dropout(0.2))\n",
    "nn.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "nn.add(keras.layers.Dropout(0.2))\n",
    "nn.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "nn.compile(optimizer=\"nadam\",\n",
    "           loss=keras.losses.categorical_crossentropy,\n",
    "           metrics=[\"accuracy\"],\n",
    "           )\n",
    "\n",
    "print(nn.summary())\n",
    "\n",
    "train = nn.fit(X1s, y1s,\n",
    "               epochs=50,\n",
    "               batch_size=10000,\n",
    "               validation_data=(X1sVal, y1sVal),\n",
    "               use_multiprocessing=True,\n",
    "               )\n",
    "\n",
    "h = train.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº of errors: 5764\n"
     ]
    }
   ],
   "source": [
    "y2e = nn.predict(X2)\n",
    "y2p = np.argmax(y2e, axis=1)\n",
    "\n",
    "print('Nº of errors:', np.sum(y2 != y2p))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b5be1fd1de7b40782a9e00e64e3cbb4863fd6c2414af64edfcd9ccb8133f2c5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
