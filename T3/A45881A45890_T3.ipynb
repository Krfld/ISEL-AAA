{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "def log(msg):\n",
    "    print(msg, '\\n')\n",
    "\n",
    "\n",
    "def createFolders():\n",
    "    for breed in list(classDic.keys()):\n",
    "        # Breeds\n",
    "        trainPath = os.path.join('./breeds/train/' + breed)\n",
    "        if not os.path.exists(trainPath):\n",
    "            os.mkdir('./breeds/train/' + breed)\n",
    "\n",
    "        testPath = os.path.join('./breeds/test/' + breed)\n",
    "        if not os.path.exists(testPath):\n",
    "            os.mkdir('./breeds/test/' + breed)\n",
    "\n",
    "        # Dogs\n",
    "        trainPath = os.path.join('./species/train/dog')\n",
    "        if not os.path.exists(trainPath):\n",
    "            os.mkdir('./species/train/dog')\n",
    "\n",
    "        testPath = os.path.join('./species/test/dog')\n",
    "        if not os.path.exists(testPath):\n",
    "            os.mkdir('./species/test/dog')\n",
    "\n",
    "        # Cats\n",
    "        trainPath = os.path.join('./species/train/cat')\n",
    "        if not os.path.exists(trainPath):\n",
    "            os.mkdir('./species/train/cat')\n",
    "\n",
    "        testPath = os.path.join('./species/test/cat')\n",
    "        if not os.path.exists(testPath):\n",
    "            os.mkdir('./species/test/cat')\n",
    "\n",
    "\n",
    "def splitBreeds():\n",
    "    for imgName in list(filesDic.keys()):\n",
    "        img = keras.preprocessing.image.load_img('images/' + imgName)\n",
    "        foldTrain = filesDic.get(imgName).get('foldTrain')\n",
    "\n",
    "        keras.preprocessing.image.save_img(\n",
    "            './breeds/' + ('train/' if foldTrain else 'test/') + filesDic.get(imgName).get('breed') + '/' + imgName, img)\n",
    "\n",
    "\n",
    "def splitSpecies():\n",
    "    for imgName in list(filesDic.keys()):\n",
    "        img = keras.preprocessing.image.load_img('images/' + imgName)\n",
    "        foldTrain = filesDic.get(imgName).get('foldTrain')\n",
    "\n",
    "        keras.preprocessing.image.save_img(\n",
    "            './species/' + ('train/' if foldTrain else 'test/') + filesDic.get(imgName).get('species') + '/' + imgName, img)\n",
    "\n",
    "\n",
    "D = dict(pickle.load(open('Oxford-IIIT-Pet_Dics.p', 'rb')))\n",
    "# log(D)\n",
    "imageNum = 7390\n",
    "\n",
    "DKeys = list(D.keys())\n",
    "# log(DKeys)\n",
    "\n",
    "classDic = dict(D.get('classDic'))\n",
    "# log(classDic)\n",
    "\n",
    "filesDic = dict(D.get('filesDic'))\n",
    "# log(list(filesDic.keys()))\n",
    "filesDicValues = list(filesDic.values())\n",
    "# log(filesDicValues[-1:])\n",
    "\n",
    "# createFolders()\n",
    "# splitBreeds()\n",
    "# splitSpecies()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speciesCnn = models.Sequential()\n",
    "\n",
    "speciesCnn.add(layers.Conv2D(6, (5, 5), activation='relu',\n",
    "                             input_shape=(224, 224, 3), padding=\"same\"))\n",
    "speciesCnn.add(layers.AveragePooling2D((2, 2)))\n",
    "speciesCnn.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "speciesCnn.add(layers.AveragePooling2D((2, 2)))\n",
    "speciesCnn.add(layers.Conv2D(120, (1, 1), activation='relu'))\n",
    "speciesCnn.add(layers.Flatten())\n",
    "speciesCnn.add(layers.Dense(64, activation='relu'))\n",
    "speciesCnn.add(layers.Dense(2, activation='softmax'))  # 2 species\n",
    "\n",
    "speciesCnn.summary()\n",
    "\n",
    "speciesCnn.compile(optimizer=\"nadam\",\n",
    "                   loss=\"categorical_crossentropy\",\n",
    "                   metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breedsCnn = models.Sequential()\n",
    "\n",
    "breedsCnn.add(layers.Conv2D(6, (5, 5), activation='relu',\n",
    "                            input_shape=(224, 224, 3), padding=\"same\"))\n",
    "breedsCnn.add(layers.AveragePooling2D((2, 2)))\n",
    "breedsCnn.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "breedsCnn.add(layers.AveragePooling2D((2, 2)))\n",
    "breedsCnn.add(layers.Conv2D(120, (1, 1), activation='relu'))\n",
    "breedsCnn.add(layers.Flatten())\n",
    "breedsCnn.add(layers.Dense(64, activation='relu'))\n",
    "breedsCnn.add(layers.Dense(37, activation='softmax'))  # 37 breeds\n",
    "\n",
    "breedsCnn.summary()\n",
    "\n",
    "breedsCnn.compile(optimizer=\"nadam\",\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using input size of 224x224 because it seems a good shape for the overall images and it's to be compatible with the mobileNet network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "mn2 = MobileNetV2(weights='imagenet',\n",
    "                  input_shape=(224, 224, 3))\n",
    "\n",
    "mn2.trainable = False\n",
    "\n",
    "# mn2.summary()\n",
    "\n",
    "breedsMn2Cnn = models.Sequential()\n",
    "breedsMn2Cnn.add(mn2)\n",
    "breedsMn2Cnn.add(layers.Flatten())\n",
    "breedsMn2Cnn.add(layers.Dense(37, activation='softmax'))  # 37 breeds\n",
    "\n",
    "breedsMn2Cnn.summary()\n",
    "\n",
    "breedsMn2Cnn.compile(optimizer=\"nadam\",\n",
    "                     loss=\"categorical_crossentropy\",\n",
    "                     metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen the mobileNetV2 because it's a network that has 3.5M parameters and makes it quick for us to train, compared to other networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generator with and without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "breedsDir = './breeds/'\n",
    "\n",
    "breedsGen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "breedsGenAug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                  rotation_range=30,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode=\"nearest\")\n",
    "\n",
    "breedsTrainGen = breedsGen.flow_from_directory(directory=breedsDir + \"train/\",\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               batch_size=32)\n",
    "\n",
    "breedsTrainGenAug = breedsGenAug.flow_from_directory(directory=breedsDir + \"train/\",\n",
    "                                                     target_size=(224, 224),\n",
    "                                                     class_mode=\"categorical\",\n",
    "                                                     batch_size=32)\n",
    "\n",
    "breedsTestGen = breedsGen.flow_from_directory(directory=breedsDir + \"test/\",\n",
    "                                              target_size=(224, 224),\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              batch_size=32)\n",
    "\n",
    "speciesDir = './species/'\n",
    "\n",
    "speciesGen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "speciesGenAug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode=\"nearest\")\n",
    "\n",
    "speciesTrainGen = speciesGen.flow_from_directory(directory=speciesDir + \"train/\",\n",
    "                                                 target_size=(224, 224),\n",
    "                                                 class_mode=\"categorical\",\n",
    "                                                 batch_size=32)\n",
    "\n",
    "speciesTrainGenAug = speciesGenAug.flow_from_directory(directory=speciesDir + \"train/\",\n",
    "                                                       target_size=(224, 224),\n",
    "                                                       class_mode=\"categorical\",\n",
    "                                                       batch_size=32)\n",
    "\n",
    "speciesTestGen = speciesGen.flow_from_directory(directory=speciesDir + \"test/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we don't augment the data for the test set\n",
    "\n",
    "If we were to use validation data, we wouldn't use data augmentation either\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary (Species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = speciesCnn.fit(speciesTrainGen,\n",
    "                     epochs=1,\n",
    "                     validation_data=speciesTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = speciesCnn.predict(speciesTestGen)\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = speciesCnn.fit(speciesTrainGenAug,\n",
    "                     epochs=25,\n",
    "                     validation_data=speciesTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = speciesCnn.predict(speciesTestGen)\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class (Breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = breedsCnn.fit(breedsTrainGen,\n",
    "                    epochs=25,\n",
    "                    validation_data=breedsTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = breedsCnn.predict(breedsTestGen)\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = breedsMn2Cnn.fit(breedsTrainGen,\n",
    "                       epochs=25,\n",
    "                       validation_data=breedsTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = breedsMn2Cnn.predict(breedsTestGen)\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class (Breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = breedsCnn.fit(breedsTrainGenAug,\n",
    "                    epochs=25,\n",
    "                    validation_data=breedsTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = breedsCnn.predict(breedsTestGen)\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = breedsMn2Cnn.fit(breedsTrainGenAug,\n",
    "                       epochs=25,\n",
    "                       validation_data=breedsTestGen)\n",
    "\n",
    "h = log.history\n",
    "plt.plot(h[\"loss\"], label='Loss')\n",
    "plt.plot(h[\"accuracy\"], label='Accuracy')\n",
    "plt.plot(h[\"val_loss\"], label='Val Loss')\n",
    "plt.plot(h[\"val_accuracy\"], label='Val Acurracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "predicted = breedsMn2Cnn.predict(breedsTestGen)\n",
    "print(predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b5be1fd1de7b40782a9e00e64e3cbb4863fd6c2414af64edfcd9ccb8133f2c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
